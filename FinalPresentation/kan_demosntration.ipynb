{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "from sklearn.datasets import make_moons\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando fórmula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "train_input, train_label = make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=0)\n",
    "test_input, test_label = make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=0)\n",
    "\n",
    "dtype = torch.get_default_dtype()\n",
    "dataset['train_input'] = torch.from_numpy(train_input).type(dtype)\n",
    "dataset['test_input'] = torch.from_numpy(test_input).type(dtype)\n",
    "dataset['train_label'] = torch.from_numpy(train_label[:, None]).type(dtype)\n",
    "dataset['test_label'] = torch.from_numpy(test_label[:, None]).type(dtype)\n",
    "\n",
    "X = dataset['train_input']\n",
    "y = dataset['train_label']\n",
    "plt.figure()\n",
    "plt.scatter(dataset['train_input'][:, 0], dataset['train_input'][:, 1], c=dataset['train_label'])\n",
    "plt.title('TRAIN')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.scatter(dataset['test_input'][:, 0], dataset['test_input'][:, 1], c=dataset['test_label'])\n",
    "plt.title('TEST')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2,5,1] means 2 inputs, 5 hidden add neurons, and 1 output\n",
    "# [2,[5,2],1] means 2 inputs, 5 hidden add neurons and 2 hidden multiplication neurons, and 1 output.\n",
    "# grid é a 'resolução' da spline\n",
    "# k é a ordem polinomial da spline\n",
    "model = KAN(width=[2, 1], grid=3, k=3)\n",
    "\n",
    "\n",
    "def train_acc():\n",
    "    return torch.mean((torch.round(model(dataset['train_input'])[:, 0]) == dataset['train_label'][:, 0]).type(dtype))\n",
    "\n",
    "\n",
    "def test_acc():\n",
    "    return torch.mean((torch.round(model(dataset['test_input'])[:, 0]) == dataset['test_label'][:, 0]).type(dtype))\n",
    "\n",
    "\n",
    "model_results = model.fit(dataset, opt=\"LBFGS\", steps=20, metrics=(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = ['x^2', 'x^3', 'x^4', 'exp', 'log', 'sqrt', 'tanh', 'sin', 'tan', 'abs']\n",
    "model.auto_symbolic(lib=lib)\n",
    "formula = model.symbolic_formula()[0][0]\n",
    "ex_round(formula, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_func = sp.lambdify(['x_1', 'x_2'], formula, \"numpy\")\n",
    "results = expr_func(dataset['test_input'][:, 0], dataset['test_input'][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sem usar auto_symbolic\n",
    "# results = model(torch.from_numpy(test_input).type(dtype)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.scatter(dataset['test_input'][:, 0], dataset['test_input'][:, 1], c=results)  # np.round(results,0)\n",
    "plt.title('PREDICTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red.csv', sep=\";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['quality'])\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.get_default_dtype()\n",
    "\n",
    "dataset = {}\n",
    "dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype)\n",
    "dataset['test_input'] = torch.from_numpy(X_test.values).type(dtype)\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "dataset['train_label'] = torch.from_numpy(encoder.fit_transform(\n",
    "    y_train.values.reshape(-1, 1)).flatten()).type(torch.LongTensor)\n",
    "dataset['test_label'] = torch.from_numpy(encoder.transform(\n",
    "    y_train.values.reshape(-1, 1)).flatten()).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KAN(width=[X_train.shape[1], 6, 6], grid=3, k=3)\n",
    "model_results = model.fit(dataset, opt=\"LBFGS\", steps=100, loss_fn=torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(torch.from_numpy(X_test.values).type(dtype)).detach().numpy()\n",
    "y_pred = encoder.inverse_transform(np.argmax(results, axis=1).reshape(-1, 1)).flatten()\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################  USANDO AUTO_SYMBOLIC ###########################\n",
    "# ################### PODE CONTER ERROS ################################\n",
    "\n",
    "# lib = ['x', 'x^2', 'x^3', 'x^4', 'exp', 'log', 'sqrt', 'tanh', 'sin', 'tan', 'abs', 'cos']\n",
    "# model.auto_symbolic(lib=lib)\n",
    "\n",
    "# func1 = model.symbolic_formula()[0][0]\n",
    "# expr_func1 = sp.lambdify(list(func1.free_symbols), formula, \"numpy\")\n",
    "# results1 = expr_func1(**{symbol.name: np.array(dataset['test_input'][:, i])\n",
    "#                       for i, symbol in enumerate(ex_round(func1, 2).free_symbols)})\n",
    "\n",
    "# func2 = model.symbolic_formula()[0][1]\n",
    "# expr_func2 = sp.lambdify(list(func2.free_symbols), formula, \"numpy\")\n",
    "# results2 = expr_func2(**{symbol.name: np.array(dataset['test_input'][:, i])\n",
    "#                       for i, symbol in enumerate(ex_round(func2, 2).free_symbols)})\n",
    "\n",
    "# func3 = model.symbolic_formula()[0][2]\n",
    "# expr_func3 = sp.lambdify(list(func3.free_symbols), formula, \"numpy\")\n",
    "# results3 = expr_func3(**{symbol.name: np.array(dataset['test_input'][:, i])\n",
    "#                       for i, symbol in enumerate(ex_round(func3, 2).free_symbols)})\n",
    "\n",
    "# func4 = model.symbolic_formula()[0][3]\n",
    "# expr_func4 = sp.lambdify(list(func4.free_symbols), formula, \"numpy\")\n",
    "# results4 = expr_func4(**{symbol.name: np.array(dataset['test_input'][:, i])\n",
    "#                       for i, symbol in enumerate(ex_round(func4, 2).free_symbols)})\n",
    "\n",
    "# func5 = model.symbolic_formula()[0][4]\n",
    "# expr_func5 = sp.lambdify(list(func5.free_symbols), formula, \"numpy\")\n",
    "# results5 = expr_func5(**{symbol.name: np.array(dataset['test_input'][:, i])\n",
    "#                       for i, symbol in enumerate(ex_round(func5, 2).free_symbols)})\n",
    "\n",
    "# func6 = model.symbolic_formula()[0][5]\n",
    "# expr_func6 = sp.lambdify(list(func6.free_symbols), formula, \"numpy\")\n",
    "# results6 = expr_func6(**{symbol.name: np.array(dataset['test_input'][:, i])\n",
    "#                       for i, symbol in enumerate(ex_round(func6, 2).free_symbols)})\n",
    "\n",
    "# y_pred = encoder.inverse_transform(\n",
    "#     np.argmax([results1, results2, results3, results4, results5, results6], axis=0).reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.scatter(np.arange(y_test.shape[0]), y_test, label='y_test')  # np.round(results,0)\n",
    "plt.scatter(np.arange(y_test.shape[0]), y_pred, label='y_pred')\n",
    "plt.title('PREDICTION')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catastrophic Forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "n_peak = 5\n",
    "n_num_per_peak = 100\n",
    "n_sample = n_peak * n_num_per_peak\n",
    "\n",
    "x_grid = torch.linspace(-1, 1, steps=n_sample)\n",
    "\n",
    "x_centers = 2/n_peak * (np.arange(n_peak) - n_peak/2+0.5)\n",
    "\n",
    "x_sample = torch.stack([torch.linspace(-1/n_peak, 1/n_peak, steps=n_num_per_peak) +\n",
    "                       center for center in x_centers]).reshape(-1,)\n",
    "\n",
    "\n",
    "y = 0.\n",
    "for center in x_centers:\n",
    "    y += torch.exp(-(x_grid-center)**2*300)\n",
    "\n",
    "y_sample = 0.\n",
    "for center in x_centers:\n",
    "    y_sample += torch.exp(-(x_sample-center)**2*300)\n",
    "\n",
    "\n",
    "plt.plot(x_grid.detach().numpy(), y.detach().numpy())\n",
    "plt.scatter(x_sample.detach().numpy(), y_sample.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "no exemplo do pykan:\n",
    "setting bias_trainable=False, sp_trainable=False, sb_trainable=False is important.\n",
    "otherwise KAN will have random scaling and shift for samples in previous stages\n",
    "\"\"\"\n",
    "\n",
    "ys = []\n",
    "model = KAN(width=[1, 1], grid=200, k=3, noise_scale=0.1, sp_trainable=False, sb_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "\n",
    "dataset['train_input'] = x_sample[group_id*n_num_per_peak:(group_id+1)*n_num_per_peak][:, None]\n",
    "dataset['train_label'] = y_sample[group_id*n_num_per_peak:(group_id+1)*n_num_per_peak][:, None]\n",
    "\n",
    "dataset['test_input'] = x_sample[group_id*n_num_per_peak:(group_id+1)*n_num_per_peak][:, None]\n",
    "dataset['test_label'] = y_sample[group_id*n_num_per_peak:(group_id+1)*n_num_per_peak][:, None]\n",
    "\n",
    "model.fit(dataset, opt='LBFGS', steps=100, update_grid=False)\n",
    "y_pred = model(x_grid[:, None])\n",
    "ys.append(y_pred.detach().numpy()[:, 0])\n",
    "plt.figure()\n",
    "plt.plot(x_grid.detach().numpy(), y.detach().numpy(), color='black', alpha=0.1)\n",
    "plt.plot(x_grid.detach().numpy(), ys[group_id], color='black')\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 2)\n",
    "group_id += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
