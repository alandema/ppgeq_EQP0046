{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u_j73SUfQxG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Physics Informed Neural Networks to Approximate Solution of PDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1679401692196,
     "user": {
      "displayName": "Roberto Molinaro",
      "userId": "05050284606345065493"
     },
     "user_tz": -60
    },
    "id": "NOPdRWmOfQxI",
    "outputId": "7e48ccf5-8b35-43b2-fa3c-ebf973323f50",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from Common import NeuralNet, MultiVariatePoly\n",
    "import time\n",
    "torch.manual_seed(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kM0O07h0fQxJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Consider the one-dimensional heat equation:\n",
    "\n",
    "$$\n",
    "u_t(t, x) = u_{xx}(t, x), \\quad t\\in[0,T], ~x\\in [-1,1]\n",
    "$$\n",
    "\n",
    "\n",
    "with zero Dirichlet boundary conditions\n",
    "\n",
    "$$\n",
    "u_b(t, -1)=u_b(t,1)=0, \n",
    "$$\n",
    "\n",
    "and initial condition\n",
    "\n",
    "$$\n",
    "u(x, 0) = u_0(x) = - \\sin(\\pi x)\n",
    "$$\n",
    "\n",
    "We want to obtain an approximate solution of the heat equation $u : [0,T]\\times[-1,1] \\mapsto \\mathbb{R}$ with physics informed neural networks (PINNs).\n",
    "\n",
    "To do so, we approximate the underlying solution with a feedforward dense neural network with tunable parameters $\\theta$:\n",
    "\n",
    "$$\n",
    "u_\\theta(t,x) \\approx u(t,x)\n",
    "$$\n",
    "Define the following residuals:\n",
    "\n",
    "   - Interior residual given by,\n",
    "\n",
    "   $$r_{int,\\theta}(t, x):=  u_{\\theta, t}(x,t) - u_{\\theta, xx}(x,t), \\quad \\forall ~t \\in [0,T],~ x \\in [-1,1].$$\n",
    "   \n",
    "        \n",
    "      \n",
    "        \n",
    "   - Spatial boundary residual given by,\n",
    "   \n",
    "        $$r_{sb,\\theta}(t,-1):= u_{\\theta}(t,-1)- u_b(t,-1), \\quad r_{sb,\\theta}(t,1):= u_{\\theta}(t,1)- u_b(t,1), \\quad \\forall t \\in (0,T].$$\n",
    "        \n",
    "   - Temporal boundary residual given by,\n",
    "   \n",
    "        $$r_{tb,\\theta}(x):= u_{\\theta}(x,0) - u_0(x), \\quad \\forall x \\in [-1,1].$$\n",
    "\n",
    "and compute the corresponding loss functions:\n",
    "\n",
    "$$\n",
    "L_{int}(\\theta) = \\int_{[0,T]\\times[-1,1]}r_{int,\\theta}^2(t, x) dtdx, \\quad\n",
    "L_{sb}(\\theta) = \\int_{[0,T]}r_{sb,\\theta}^2(t,-1) dt + \\int_{[0,T]}r_{sb,\\theta}^2(t,1)dt, \\quad\n",
    "L_{tb}(\\theta) = \\int_{[-1,1]}r_{tb,\\theta}^2(x) dx\n",
    "$$\n",
    "\n",
    "The loss functions include integrals that can be approximated by suitable quadrature rule. We use quasi Monte-Carlo and accordingly define the following training sets\n",
    "\n",
    "$$\n",
    "S_{int} =\\{y_n\\}, \\quad 1 \\leq n \\leq N_{int},\\quad y_n = (x,t)_n \\in D_T,\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_{sb, -1} =\\{t_n, u_b(t_n,-1) \\}, \\quad1 \\leq n \\leq N_{sb}, t_n \\in [0,T],\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_{sb, 1} =\\{t_n, u_b(t_n,1) \\}, \\quad1 \\leq n \\leq N_{sb}, t_n \\in [0,T],\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_{tb}=\\{x_n, u_0(x_n)\\}\\quad  1 \\leq n \\leq N_{tb}, x_n \\in [-1,1].\n",
    "$$\n",
    "\n",
    "with the training inputs points corresponding to low-discrepancy Sobol sequences.\n",
    "\n",
    "$$\n",
    "L_{int}(\\theta) = \\frac{1}{N_{int}}\\sum_{i=1}^{N_{int}}r_{int,\\theta}^2(y_n), \\quad\n",
    "L_{sb}(\\theta) = \\frac{1}{N_{sb}}\\sum_{i=1}^{N_{sb}}r_{sb,\\theta}^2(t_n,-1) + \\frac{1}{N_{sb}}\\sum_{i=1}^{N_{sb}}r_{sb,\\theta}^2(t_n,1), \\quad\n",
    "L_{tb}(\\theta) = \\frac{1}{N_{tb}}\\sum_{i=1}^{N_{tb}}r_{tb,\\theta}^2(x_n)\n",
    "$$\n",
    "\n",
    "and solve the following minimization problem\n",
    "\n",
    "$$\n",
    "\\theta^\\ast = argmin_{\\theta} \\Big(L_{int}(\\theta) + \\lambda_u L_u(\\theta)\\Big)\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "L_u(\\theta) = L_{tb}(\\theta) + L_{sb}(\\theta)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1679403218293,
     "user": {
      "displayName": "Roberto Molinaro",
      "userId": "05050284606345065493"
     },
     "user_tz": -60
    },
    "id": "HgRzd8_wfQxK",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pinns:\n",
    "    def __init__(self, n_int_, n_sb_, n_tb_):\n",
    "        self.n_int = n_int_\n",
    "        self.n_sb = n_sb_\n",
    "        self.n_tb = n_tb_\n",
    "\n",
    "        # Extrema of the solution domain (t,x) in [0,0.1]x[-1,1]\n",
    "        self.domain_extrema = torch.tensor([[0, 0.6],  # Time dimension\n",
    "                                            [-1, 1]])  # Space dimension\n",
    "\n",
    "        # Number of space dimensions\n",
    "        self.space_dimensions = 1\n",
    "\n",
    "        # Parameter to balance role of data and PDE\n",
    "        self.lambda_u = 10\n",
    "\n",
    "        # F Dense NN to approximate the solution of the underlying heat equation\n",
    "        self.approximate_solution = NeuralNet(input_dimension=self.domain_extrema.shape[0], output_dimension=1,\n",
    "                                              n_hidden_layers=4,\n",
    "                                              neurons=20,\n",
    "                                              regularization_param=0.,\n",
    "                                              regularization_exp=2.,\n",
    "                                              retrain_seed=42)\n",
    "        '''self.approximate_solution = MultiVariatePoly(self.domain_extrema.shape[0], 3)'''\n",
    "\n",
    "        # Generator of Sobol sequences\n",
    "        self.soboleng = torch.quasirandom.SobolEngine(dimension=self.domain_extrema.shape[0])\n",
    "\n",
    "        # Training sets S_sb, S_tb, S_int as torch dataloader\n",
    "        self.training_set_sb, self.training_set_tb, self.training_set_int = self.assemble_datasets()\n",
    "\n",
    "    ################################################################################################\n",
    "    # Function to linearly transform a tensor whose value are between 0 and 1\n",
    "    # to a tensor whose values are between the domain extrema\n",
    "    def convert(self, tens):\n",
    "        assert (tens.shape[1] == self.domain_extrema.shape[0])\n",
    "        return tens * (self.domain_extrema[:, 1] - self.domain_extrema[:, 0]) + self.domain_extrema[:, 0]\n",
    "\n",
    "    # Initial condition to solve the heat equation u0(x)=-sin(pi x)\n",
    "    def initial_condition(self, x):\n",
    "        return -torch.sin(np.pi * x)\n",
    "\n",
    "    # Exact solution for the heat equation ut = u_xx with the IC above\n",
    "    def exact_solution(self, inputs):\n",
    "        t = inputs[:, 0]\n",
    "        x = inputs[:, 1]\n",
    "\n",
    "        u = -torch.exp(-np.pi ** 2 * t) * torch.sin(np.pi * x)\n",
    "        return u\n",
    "\n",
    "    ################################################################################################\n",
    "    # Function returning the input-output tensor required to assemble the training set S_tb corresponding to the temporal boundary\n",
    "    def add_temporal_boundary_points(self):\n",
    "        t0 = self.domain_extrema[0, 0]\n",
    "        input_tb = self.convert(self.soboleng.draw(self.n_tb))\n",
    "        input_tb[:, 0] = torch.full(input_tb[:, 0].shape, t0)\n",
    "        output_tb = self.initial_condition(input_tb[:, 1]).reshape(-1, 1)\n",
    "\n",
    "        return input_tb, output_tb\n",
    "\n",
    "    # Function returning the input-output tensor required to assemble the training set S_sb corresponding to the spatial boundary\n",
    "    def add_spatial_boundary_points(self):\n",
    "        x0 = self.domain_extrema[1, 0]\n",
    "        xL = self.domain_extrema[1, 1]\n",
    "\n",
    "        input_sb = self.convert(self.soboleng.draw(self.n_sb))\n",
    "\n",
    "        input_sb_0 = torch.clone(input_sb)\n",
    "        input_sb_0[:, 1] = torch.full(input_sb_0[:, 1].shape, x0)\n",
    "\n",
    "        input_sb_L = torch.clone(input_sb)\n",
    "        input_sb_L[:, 1] = torch.full(input_sb_L[:, 1].shape, xL)\n",
    "\n",
    "        output_sb_0 = torch.zeros((input_sb.shape[0], 1))\n",
    "        output_sb_L = torch.zeros((input_sb.shape[0], 1))\n",
    "\n",
    "        return torch.cat([input_sb_0, input_sb_L], 0), torch.cat([output_sb_0, output_sb_L], 0)\n",
    "\n",
    "    #  Function returning the input-output tensor required to assemble the training set S_int corresponding to the interior domain where the PDE is enforced\n",
    "    def add_interior_points(self):\n",
    "        input_int = self.convert(self.soboleng.draw(self.n_int))\n",
    "        output_int = torch.zeros((input_int.shape[0], 1))\n",
    "        return input_int, output_int\n",
    "\n",
    "    # Function returning the training sets S_sb, S_tb, S_int as dataloader\n",
    "    def assemble_datasets(self):\n",
    "        input_sb, output_sb = self.add_spatial_boundary_points()   # S_sb\n",
    "        input_tb, output_tb = self.add_temporal_boundary_points()  # S_tb\n",
    "        input_int, output_int = self.add_interior_points()         # S_int\n",
    "\n",
    "        training_set_sb = DataLoader(torch.utils.data.TensorDataset(input_sb, output_sb),\n",
    "                                     batch_size=2*self.space_dimensions*self.n_sb, shuffle=False)\n",
    "        training_set_tb = DataLoader(torch.utils.data.TensorDataset(\n",
    "            input_tb, output_tb), batch_size=self.n_tb, shuffle=False)\n",
    "        training_set_int = DataLoader(torch.utils.data.TensorDataset(\n",
    "            input_int, output_int), batch_size=self.n_int, shuffle=False)\n",
    "\n",
    "        return training_set_sb, training_set_tb, training_set_int\n",
    "\n",
    "    ################################################################################################\n",
    "    # Function to compute the terms required in the definition of the TEMPORAL boundary residual\n",
    "    def apply_initial_condition(self, input_tb):\n",
    "        u_pred_tb = self.approximate_solution(input_tb)\n",
    "        return u_pred_tb\n",
    "\n",
    "    # Function to compute the terms required in the definition of the SPATIAL boundary residual\n",
    "    def apply_boundary_conditions(self, input_sb):\n",
    "        u_pred_sb = self.approximate_solution(input_sb)\n",
    "\n",
    "        return u_pred_sb\n",
    "\n",
    "    # Function to compute the PDE residuals\n",
    "    def compute_pde_residual(self, input_int):\n",
    "        input_int.requires_grad = True\n",
    "        u = self.approximate_solution(input_int)\n",
    "\n",
    "        # grad compute the gradient of a \"SCALAR\" function L with respect to some input nxm TENSOR Z=[[x1, y1],[x2,y2],[x3,y3],...,[xn,yn]], m=2\n",
    "        # it returns grad_L = [[dL/dx1, dL/dy1],[dL/dx2, dL/dy2],[dL/dx3, dL/dy3],...,[dL/dxn, dL/dyn]]\n",
    "        # Note: pytorch considers a tensor [u1, u2,u3, ... ,un] a vectorial function\n",
    "        # whereas sum_u = u1 + u2 + u3 + u4 + ... + un as a \"scalar\" one\n",
    "\n",
    "        # In our case ui = u(xi), therefore the line below returns:\n",
    "        # grad_u = [[dsum_u/dx1, dsum_u/dy1],[dsum_u/dx2, dsum_u/dy2],[dsum_u/dx3, dL/dy3],...,[dsum_u/dxm, dsum_u/dyn]]\n",
    "        # and dsum_u/dxi = d(u1 + u2 + u3 + u4 + ... + un)/dxi = d(u(x1) + u(x2) u3(x3) + u4(x4) + ... + u(xn))/dxi = dui/dxi\n",
    "        grad_u = torch.autograd.grad(u.sum(), input_int, create_graph=True)[0]\n",
    "        grad_u_t = grad_u[:, 0]\n",
    "        grad_u_x = grad_u[:, 1]\n",
    "        grad_u_xx = torch.autograd.grad(grad_u_x.sum(), input_int, create_graph=True)[0][:, 1]\n",
    "\n",
    "  #      grad_u_sq_x = torch.autograd.grad(u_sq.sum(), input_int, create_graph=True)[0][:,1]\n",
    "\n",
    "        residual = grad_u_t - grad_u_xx\n",
    "        return residual.reshape(-1, )\n",
    "\n",
    "    # Function to compute the total loss (weighted sum of spatial boundary loss, temporal boundary loss and interior loss)\n",
    "    def compute_loss(self, inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=True):\n",
    "        u_pred_sb = self.apply_boundary_conditions(inp_train_sb)\n",
    "        u_pred_tb = self.apply_initial_condition(inp_train_tb)\n",
    "\n",
    "        assert (u_pred_sb.shape[1] == u_train_sb.shape[1])\n",
    "        assert (u_pred_tb.shape[1] == u_train_tb.shape[1])\n",
    "\n",
    "        r_int = self.compute_pde_residual(inp_train_int)\n",
    "        r_sb = u_train_sb - u_pred_sb\n",
    "        r_tb = u_train_tb - u_pred_tb\n",
    "\n",
    "        loss_sb = torch.mean(abs(r_sb) ** 2)\n",
    "        loss_tb = torch.mean(abs(r_tb) ** 2)\n",
    "        loss_int = torch.mean(abs(r_int) ** 2)\n",
    "\n",
    "        loss_u = loss_sb + loss_tb\n",
    "\n",
    "        loss = torch.log10(self.lambda_u * (loss_sb + loss_tb) + loss_int)\n",
    "        if verbose:\n",
    "            print(\"Total loss: \", round(loss.item(), 4), \"| PDE Loss: \", round(torch.log10(\n",
    "                loss_u).item(), 4), \"| Function Loss: \", round(torch.log10(loss_int).item(), 4))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    ################################################################################################\n",
    "    def fit(self, num_epochs, optimizer, verbose=True):\n",
    "        history = list()\n",
    "\n",
    "        # Loop over epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            if verbose:\n",
    "                print(\"################################ \", epoch, \" ################################\")\n",
    "\n",
    "            for j, ((inp_train_sb, u_train_sb), (inp_train_tb, u_train_tb), (inp_train_int, u_train_int)) in enumerate(zip(self.training_set_sb, self.training_set_tb, self.training_set_int)):\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = self.compute_loss(inp_train_sb, u_train_sb, inp_train_tb,\n",
    "                                             u_train_tb, inp_train_int, verbose=verbose)\n",
    "                    loss.backward()\n",
    "\n",
    "                    history.append(loss.item())\n",
    "                    return loss\n",
    "\n",
    "                optimizer.step(closure=closure)\n",
    "\n",
    "        print('Final Loss: ', history[-1])\n",
    "\n",
    "        return history\n",
    "\n",
    "    ################################################################################################\n",
    "    def plotting(self):\n",
    "        inputs = self.soboleng.draw(100000)\n",
    "        inputs = self.convert(inputs)\n",
    "\n",
    "        output = self.approximate_solution(inputs).reshape(-1, )\n",
    "        exact_output = self.exact_solution(inputs).reshape(-1, )\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=150)\n",
    "        im1 = axs[0].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=exact_output.detach(), cmap=\"jet\")\n",
    "        axs[0].set_xlabel(\"x\")\n",
    "        axs[0].set_ylabel(\"t\")\n",
    "        plt.colorbar(im1, ax=axs[0])\n",
    "        axs[0].grid(True, which=\"both\", ls=\":\")\n",
    "        im2 = axs[1].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=output.detach(), cmap=\"jet\")\n",
    "        axs[1].set_xlabel(\"x\")\n",
    "        axs[1].set_ylabel(\"t\")\n",
    "        plt.colorbar(im2, ax=axs[1])\n",
    "        axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "        axs[0].set_title(\"Exact Solution\")\n",
    "        axs[1].set_title(\"Approximate Solution\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        err = (torch.mean((output - exact_output) ** 2) / torch.mean(exact_output ** 2)) ** 0.5 * 100\n",
    "        print(\"L2 Relative Error Norm: \", err.item(), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1679403192490,
     "user": {
      "displayName": "Roberto Molinaro",
      "userId": "05050284606345065493"
     },
     "user_tz": -60
    },
    "id": "M3ug4ztBfQxM",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Solve the heat equation:\n",
    "# u_t = u_xx, (t,x) in [0, 0.1]x[-1,1]\n",
    "# with zero dirichlet BC and\n",
    "# u(x,0)= -sin(pi x)\n",
    "\n",
    "n_int = 256\n",
    "n_sb = 64\n",
    "n_tb = 64\n",
    "\n",
    "pinn = Pinns(n_int, n_sb, n_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1679401764229,
     "user": {
      "displayName": "Roberto Molinaro",
      "userId": "05050284606345065493"
     },
     "user_tz": -60
    },
    "id": "l4gxwi51fQxM",
    "outputId": "048a7506-4f92-447d-e58d-e39f05548b23",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the input training points\n",
    "input_sb_, output_sb_ = pinn.add_spatial_boundary_points()\n",
    "input_tb_, output_tb_ = pinn.add_temporal_boundary_points()\n",
    "input_int_, output_int_ = pinn.add_interior_points()\n",
    "\n",
    "plt.figure(figsize=(16, 8), dpi=150)\n",
    "plt.scatter(input_sb_[:, 1].detach().numpy(), input_sb_[:, 0].detach().numpy(), label=\"Boundary Points\")\n",
    "plt.scatter(input_int_[:, 1].detach().numpy(), input_int_[:, 0].detach().numpy(), label=\"Interior Points\")\n",
    "plt.scatter(input_tb_[:, 1].detach().numpy(), input_tb_[:, 0].detach().numpy(), label=\"Initial Points\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"t\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1679403222417,
     "user": {
      "displayName": "Roberto Molinaro",
      "userId": "05050284606345065493"
     },
     "user_tz": -60
    },
    "id": "0CPnHdKtfQxN",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "optimizer_LBFGS = optim.LBFGS(pinn.approximate_solution.parameters(),\n",
    "                              lr=float(0.5),\n",
    "                              max_iter=50000,\n",
    "                              max_eval=50000,\n",
    "                              history_size=150,\n",
    "                              line_search_fn=\"strong_wolfe\",\n",
    "                              tolerance_change=1.0 * np.finfo(float).eps)\n",
    "optimizer_ADAM = optim.Adam(pinn.approximate_solution.parameters(),\n",
    "                            lr=float(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 452280,
     "status": "ok",
     "timestamp": 1679403677083,
     "user": {
      "displayName": "Roberto Molinaro",
      "userId": "05050284606345065493"
     },
     "user_tz": -60
    },
    "id": "qub-M5jqfQxN",
    "outputId": "6cf2b62f-f8f2-4e80-b0c4-c3a736fa93eb",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = pinn.fit(num_epochs=n_epochs,\n",
    "                optimizer=optimizer_LBFGS,\n",
    "                verbose=True)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 18306,
     "status": "ok",
     "timestamp": 1679403731292,
     "user": {
      "displayName": "Roberto Molinaro",
      "userId": "05050284606345065493"
     },
     "user_tz": -60
    },
    "id": "3HG9DQM5fQxN",
    "outputId": "7aafd9d3-4ccb-40eb-fd91-185602c79aba",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pinn.plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1679393536192,
     "user": {
      "displayName": "Roberto Molinaro",
      "userId": "05050284606345065493"
     },
     "user_tz": -60
    },
    "id": "U_q8DqdznK6z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
